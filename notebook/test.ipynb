{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rethinking Search:  Making Experts out of Dile...</td>\n",
       "      <td>When experiencing an information need, users w...</td>\n",
       "      <td>Rethinking Search:  Making Experts out of Dile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scaling Up Visual and Vision-Language Represen...</td>\n",
       "      <td>Pre-trained representations are becoming cruci...</td>\n",
       "      <td>Scaling Up Visual and Vision-Language Represen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Rethinking Search:  Making Experts out of Dile...   \n",
       "1  Scaling Up Visual and Vision-Language Represen...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  When experiencing an information need, users w...   \n",
       "1  Pre-trained representations are becoming cruci...   \n",
       "\n",
       "                                                text  \n",
       "0  Rethinking Search:  Making Experts out of Dile...  \n",
       "1  Scaling Up Visual and Vision-Language Represen...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "data = data[['title', 'abstract']]\n",
    "data['text'] = data['title'] + '[SEP]' + data['abstract']\n",
    "\n",
    "print(data.shape)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 20:26:31 INFO: Load pretrained SentenceTransformer: allenai-specter\n",
      "2022-01-05 20:26:49 INFO: Use pytorch device: cuda\n",
      "2022-01-05 20:26:49 INFO: Missing data detected. Dropping them\n",
      "2022-01-05 20:26:49 INFO: ========== Step1: Calculating Embeddings ==========\n",
      "Batches: 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
      "2022-01-05 20:26:52 INFO: ========== Step2: Topic modeling ==========\n",
      "2022-01-05 20:26:52 INFO: Initializing the topic model\n",
      "2022-01-05 20:26:52 INFO: Training the topic model\n",
      "2022-01-05 20:26:54,313 - BERTopic - Reduced dimensionality with UMAP\n",
      "2022-01-05 20:26:54,324 - BERTopic - Clustered UMAP embeddings with HDBSCAN\n",
      "2022-01-05 20:26:54 INFO: Populating Topic Results\n",
      "2022-01-05 20:26:54 INFO: ========== Step3: STriP Network ==========\n",
      "2022-01-05 20:26:54 INFO: Cosine similarity\n",
      "2022-01-05 20:26:54 INFO: Calculating optimal threshold\n",
      "2022-01-05 20:26:54 INFO: Number of connections: 126\n",
      "2022-01-05 20:26:54 INFO: Calculating Network Plot\n",
      "2022-01-05 20:26:54 INFO: ========== Model Fit Successfully! ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening in existing browser session.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the StripNet\n",
    "from stripnet import StripNet\n",
    "stripnet = StripNet()\n",
    "\n",
    "# Run the StripNet pipeline\n",
    "stripnet.fit_transform(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 20:07:00 INFO: Calculating Network Centrality\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "customdata": [
          [
           "Deep contextualized word representations<br><br>We<br>introduce a new type of deep contextual-ized word<br>representation that models both (1) complex<br>characteristics of word use (e.g., syntax and<br>semantics), and (2) how these uses vary across<br>linguistic contexts (i.e., to model polysemy). Our<br>word vectors are learned functions of the internal<br>states of a deep bidirec-tional language model<br>(biLM), which is pre-trained on a large text<br>corpus. We show that these representation..."
          ],
          [
           "skweak: Weak Supervision Made Easy for<br>NLP<br><br>We present skweak, a versatile, Python-<br>based software toolkit enabling NLP developers to<br>apply weak supervision to a wide range of NLP<br>tasks. Weak supervision is an emerging machine<br>learning paradigm based on a simple idea: instead<br>of labelling data points by hand, we use labelling<br>functions derived from domain knowledge to<br>automatically obtain annotations for a given<br>dataset. The resulting labels are then aggregated<b..."
          ],
          [
           "Want To Reduce Labeling Cost? GPT-3 Can<br>Help<br><br>Data annotation is a time-consuming<br>and labor-intensive process for many NLP tasks.<br>Although there exist various methods to produce<br>pseudo data labels, they are often task-specific<br>and require a decent amount of labeled data to<br>start with. Recently, the immense language model<br>GPT-3 with 175 billion parameters has achieved<br>tremendous improvement across many few-shot<br>learning tasks. In this paper, we explore ways to<br>..."
          ],
          [
           "Neural Machine Translation of Rare Words with<br>Subword Units<br><br>Neural machine translation<br>(NMT) models typically operate with a fixed<br>vocabulary , but translation is an open-vocabulary<br>problem. Previous work addresses the translation<br>of out-of-vocabulary words by backing off to a<br>dictionary. In this paper , we introduce a simpler<br>and more effective approach, making the NMT model<br>capable of open-vocabulary translation by encoding<br>rare and unknown words as sequences ..."
          ]
         ],
         "hovertemplate": "Topic_Name=data, models, learning, training<br>Betweenness Centrality=%{x}<br>index=%{y}<br>Text=%{customdata[0]}<extra></extra>",
         "legendgroup": "data, models, learning, training",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "data, models, learning, training",
         "offsetgroup": "data, models, learning, training",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          0.10673251529415916,
          0.09934333324744282,
          0.07184737801176154,
          0.042019416676950916
         ],
         "xaxis": "x",
         "y": [
          "5",
          "24",
          "59",
          "7"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "customdata": [
          [
           "An Image is Worth 16x16 Words: Transformers for<br>Image Recognition at Scale<br><br>While the<br>Transformer architecture has become the de-facto<br>standard for natural language processing tasks,<br>its applications to computer vision remain<br>limited. In vision, attention is either applied in<br>conjunction with convolutional networks, or used<br>to replace certain components of convolutional<br>networks while keeping their overall structure in<br>place. We show that this reliance on CNNs is..."
          ],
          [
           "Unsupervised Data Augmentation for Consistency<br>Training<br><br>Semi-supervised learning lately<br>has shown much promise in improving deep learning<br>models when labeled data is scarce. Common among<br>recent approaches is the use of consistency<br>training on a large amount of unlabeled data to<br>constrain model predictions to be invariant to<br>input noise. In this work, we present a new<br>perspective on how to effectively noise unlabeled<br>examples and argue that the quality of noising..."
          ],
          [
           "The 2021 Image Similarity Dataset and<br>Challenge<br><br>This paper introduces a new<br>benchmark for large-scale image similarity<br>detection. This benchmark is used for the Image<br>Similarity Challenge at NeurIPS'21 (ISC2021). The<br>goal is to determine whether a query image is a<br>modified copy of any image in a reference corpus<br>of size 1~million. The benchmark features a<br>variety of image transformations such as automated<br>transformations, hand-crafted image edits and<br>machine-..."
          ],
          [
           "Scaling Up Visual and Vision-Language<br>Representation Learning With Noisy Text<br>Supervision<br><br>Pre-trained representations are<br>becoming crucial for many NLP and perception<br>tasks. While representation learning in NLP has<br>transitioned to training on raw text without human<br>annotations, visual and vision-language<br>representations still rely heavily on curated<br>training datasets that are expensive or require<br>expert knowledge. For vision applications ,<br>representations are..."
          ],
          [
           "Learning Transferable Visual Models From Natural<br>Language Supervision<br><br>State-of-the-art<br>computer vision systems are trained to predict a<br>fixed set of predetermined object categories. This<br>restricted form of supervision limits their<br>generality and usability since additional labeled<br>data is needed to specify any other visual<br>concept. Learning directly from raw text about<br>images is a promising alternative which leverages<br>a much broader source of supervision. We<br>d..."
          ]
         ],
         "hovertemplate": "Topic_Name=image, vision, learning, visual<br>Betweenness Centrality=%{x}<br>index=%{y}<br>Text=%{customdata[0]}<extra></extra>",
         "legendgroup": "image, vision, learning, visual",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "image, vision, learning, visual",
         "offsetgroup": "image, vision, learning, visual",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          0.07375869019704637,
          0.06015364679748239,
          0.059237319511292116,
          0.053904344657769304,
          0.03623643212684308
         ],
         "xaxis": "x",
         "y": [
          "57",
          "18",
          "42",
          "1",
          "34"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "customdata": [
          [
           "FNet: Mixing Tokens with Fourier<br>Transforms<br><br>We show that Transformer encoder<br>architec-tures can be massively sped up, with<br>limited accuracy costs, by replacing the self-<br>attention sublayers with simple linear<br>transformations that \"mix\" input tokens. These<br>linear transformations , along with simple<br>nonlinearities in feed-forward layers, are<br>sufficient to model semantic relationships in<br>several text classification tasks. Perhaps most<br>surprisingly, we find that ..."
          ]
         ],
         "hovertemplate": "Topic_Name=image, matching, similarity, copy<br>Betweenness Centrality=%{x}<br>index=%{y}<br>Text=%{customdata[0]}<extra></extra>",
         "legendgroup": "image, matching, similarity, copy",
         "marker": {
          "color": "#00cc96",
          "pattern": {
           "shape": ""
          }
         },
         "name": "image, matching, similarity, copy",
         "offsetgroup": "image, matching, similarity, copy",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          0.05168250442223043
         ],
         "xaxis": "x",
         "y": [
          "8"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "font": {
         "size": 15
        },
        "height": 800,
        "legend": {
         "title": {
          "text": "Topic_Name"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Betweenness Centrality"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryorder": "total ascending",
         "domain": [
          0,
          1
         ],
         "showticklabels": false,
         "title": {
          "text": "index"
         },
         "visible": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stripnet.most_important()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "165d1ae889830a583229da7bcb4f0175182080283a5d782889056a279531f3b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('stripnet': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
